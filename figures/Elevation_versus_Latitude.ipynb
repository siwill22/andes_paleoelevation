{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e899fbff-a52a-417b-9b81-3bd806c10b14",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR 1: PROJ: proj_identify: Cannot find proj.db\n",
      "ERROR 1: PROJ: proj_create_from_database: Cannot find proj.db\n",
      "ERROR 1: PROJ: proj_identify: Cannot find proj.db\n",
      "ERROR 1: PROJ: proj_create_from_database: Cannot find proj.db\n",
      "ERROR 1: PROJ: proj_identify: Cannot find proj.db\n",
      "ERROR 1: PROJ: proj_create_from_database: Cannot find proj.db\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "import matplotlib.pyplot as plt\n",
    "import pygplates\n",
    "import pygmt\n",
    "\n",
    "from scipy.interpolate import RegularGridInterpolator\n",
    "from gprm import ReconstructionModel\n",
    "from gprm.datasets import Rocks, Reconstructions, Paleogeography, Geology\n",
    "from gprm.utils.raster import to_anchor_plate\n",
    "from gprm.utils.fileio import load_netcdf\n",
    "\n",
    "import sys\n",
    "#sys.path.append('/Users/simon/OneDrive/Andes_works//python/')\n",
    "sys.path.append('../python/')\n",
    "import joyful_geochemistry as joy\n",
    "import joyful_mapping as joymap\n",
    "\n",
    "import collections\n",
    "from scipy.stats import median_abs_deviation\n",
    "\n",
    "import matplotlib as mpl\n",
    "mpl.rc('font',family='Helvetica')\n",
    "mpl.rcParams['axes.linewidth'] = 2\n",
    "mpl.rcParams['xtick.major.width'] = 2\n",
    "mpl.rcParams['ytick.major.width'] = 2\n",
    "\n",
    "%matplotlib inline\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "\n",
    "############## Settings for Scotese Paleomap\n",
    "PaleomapDictionary = {}\n",
    "PaleomapDictionary['name'] = 'Paleomap'\n",
    "PaleomapDictionary['reconstruction_model'] = Reconstructions.fetch_Scotese()\n",
    "PaleomapDictionary['raster_sequence'] = Paleogeography.fetch_Paleomap()\n",
    "PaleomapDictionary['maximum_time'] = 350.\n",
    "PaleomapDictionary['time_bin_size'] = 10.\n",
    "PaleomapDictionary['anchor_plate_id'] = 201\n",
    "PaleomapDictionary['raster_anchor_plate_id'] = 0\n",
    "\n",
    "#Paleomap = Reconstructions.fetch_Scotese()\n",
    "#PaleoDEM = Paleogeography.fetch_Paleomap()\n",
    "\n",
    "\n",
    "############## Settings for Boschman model\n",
    "boschman_rotation_model = ReconstructionModel('')\n",
    "boschman_rotation_model.add_rotation_model('/Users/simon/GIT/bx/andes//boschman/reconstruction_model/boschman_reverse_engineered_rotations.rot')\n",
    "boschman_rotation_model.add_static_polygons('/Users/simon/GIT/bx/andes//boschman/reconstruction_model/reconstructed_0.00Ma.shp')\n",
    "\n",
    "raster_dict = {}\n",
    "for reconstruction_time in np.arange(0,81,1):\n",
    "    raster_dict[reconstruction_time] = '/Users/simon/GIT/bx/andes//boschman/grids/boschman_DEM_{:0.0f}Ma.nc'.format(reconstruction_time)\n",
    "boschman_rasters = collections.OrderedDict(sorted(raster_dict.items()))\n",
    "\n",
    "\n",
    "BoschmanDictionary = {}\n",
    "BoschmanDictionary['name'] = 'Boschman'\n",
    "BoschmanDictionary['reconstruction_model'] = boschman_rotation_model\n",
    "BoschmanDictionary['raster_sequence'] = boschman_rasters\n",
    "BoschmanDictionary['maximum_time'] = 80.\n",
    "BoschmanDictionary['time_bin_size'] = 5.\n",
    "BoschmanDictionary['anchor_plate_id'] = 201\n",
    "BoschmanDictionary['raster_anchor_plate_id'] = 201\n",
    "\n",
    "\n",
    "########## Geochemistry Inputs\n",
    "df = joy.geochem_from_csv('../datafiles/geochem_merge_20221026.csv',\n",
    "                          longitude_field_name='Longitude', latitude_field_name='Latitude')\n",
    "\n",
    "model_dir = '../luffi/REM_surfaces_csv/'\n",
    "gc_interpolator_dict = joy.make_gc_interpolator_dict(model_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d40a3d76-6a9b-4d82-8592-eac34bf05bf2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#TODO\n",
    "# Specify rounding on call\n",
    "# Put assign inside function\n",
    "\n",
    "# THE SCIPY INTERP COULD BE IN SPHERICAL COORDS??\n",
    "\n",
    "# Calling grdtrack per individual point is slow, so use a caretsian interp \n",
    "\n",
    "def generate_time_dependent_interpolator(raster_sequence):\n",
    "    #print(raster_sequence.keys())\n",
    "    interpolator_dict = {}\n",
    "    for reconstruction_time in raster_sequence.keys():\n",
    "        gridX,gridY,gridZ = load_netcdf(raster_sequence[reconstruction_time])\n",
    "        interpolator_dict[reconstruction_time] = RegularGridInterpolator((gridX,gridY), gridZ.T, \n",
    "                                                                         method='linear',\n",
    "                                                                         bounds_error=False,\n",
    "                                                                         fill_value = np.nan)\n",
    "    return interpolator_dict\n",
    "    \n",
    "\n",
    "def interpolate_paleoDEM(df, reconstruction_model, raster_sequence,\n",
    "                         anchor_plate_id): #, raster_anchor_plate_id=0):\n",
    "    reconstructed_coordinates = []\n",
    "    interpolated_paleoDEM = []\n",
    "    for i,row in df.iterrows():\n",
    "        reconstruction_time = np.round(row.age/5)*5\n",
    "        rotation = reconstruction_model.rotation_model.get_rotation(\n",
    "            reconstruction_time,\n",
    "            row['PLATEID1'],\n",
    "            anchor_plate_id=anchor_plate_id)\n",
    "        reconstructed_geometry = rotation * pygplates.PointOnSphere(row.Latitude, row.Longitude)\n",
    "        reconstructed_coordinates.append(reconstructed_geometry.to_lat_lon())\n",
    "        result = interpolator_dict[reconstruction_time]([reconstructed_geometry.to_lat_lon()[1], \n",
    "                                                         reconstructed_geometry.to_lat_lon()[0]])\n",
    "        interpolated_paleoDEM.append(result[0])\n",
    "    df['PaleoDEM'] = interpolated_paleoDEM\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "30aa656d-4bf0-42ab-81dc-7155ca6fe6b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = joymap.select_orogens(df,gdf=None, \n",
    "                           orogen_names='Cordilleran', \n",
    "                           continent_names='South America',\n",
    "                           region=[-100, -50, -60, 20])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "67a392b5-bd2e-40c6-9642-7fbe3cc15f56",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of samples after basic filtering 21276\n",
      "Final number of samples passed = 16213\n",
      "TODO implement min/max elevation cutoffs\n",
      "TODO implement min/max elevation cutoffs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/k2/jz_0twls1q13vbr87bqwdtr40000gn/T/ipykernel_96230/1202376196.py:166: FutureWarning: In a future version of pandas, a length 1 tuple will be returned when iterating over a groupby with a grouper equal to a list of length 1. Don't supply a list with a single grouper to avoid this warning.\n",
      "  for group in time_binned:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of samples after basic filtering 21276\n",
      "Final number of samples passed = 16213\n",
      "TODO implement min/max elevation cutoffs\n",
      "TODO implement min/max elevation cutoffs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/k2/jz_0twls1q13vbr87bqwdtr40000gn/T/ipykernel_96230/1202376196.py:166: FutureWarning: In a future version of pandas, a length 1 tuple will be returned when iterating over a groupby with a grouper equal to a list of length 1. Don't supply a list with a single grouper to avoid this warning.\n",
      "  for group in time_binned:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of samples after basic filtering 21276\n",
      "Number of samples with 55<=sio2<=70 = 9991\n",
      "Number of these samples with 1<=mgo<=4 = 7694\n",
      "Number of these samples with 0.05<=rb/sr<=0.25 = 4253\n",
      "Final number of samples passed = 4253\n",
      "TODO implement min/max elevation cutoffs\n",
      "TODO implement min/max elevation cutoffs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/k2/jz_0twls1q13vbr87bqwdtr40000gn/T/ipykernel_96230/1202376196.py:166: FutureWarning: In a future version of pandas, a length 1 tuple will be returned when iterating over a groupby with a grouper equal to a list of length 1. Don't supply a list with a single grouper to avoid this warning.\n",
      "  for group in time_binned:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of samples after basic filtering 21276\n",
      "Number of samples with 55<=sio2<=70 = 9991\n",
      "Number of these samples with 1<=mgo<=4 = 7694\n",
      "Number of these samples with 0.05<=rb/sr<=0.25 = 4253\n",
      "Final number of samples passed = 4253\n",
      "TODO implement min/max elevation cutoffs\n",
      "TODO implement min/max elevation cutoffs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/k2/jz_0twls1q13vbr87bqwdtr40000gn/T/ipykernel_96230/1202376196.py:166: FutureWarning: In a future version of pandas, a length 1 tuple will be returned when iterating over a groupby with a grouper equal to a list of length 1. Don't supply a list with a single grouper to avoid this warning.\n",
      "  for group in time_binned:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of samples after basic filtering 21276\n",
      "Number of these samples with a valid sio2 = 16666\n",
      "Number of these samples with major element sum > 98%= 10638\n",
      "Final number of samples passed = 10638\n",
      "TODO implement min/max elevation cutoffs\n",
      "TODO implement min/max elevation cutoffs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/k2/jz_0twls1q13vbr87bqwdtr40000gn/T/ipykernel_96230/1202376196.py:166: FutureWarning: In a future version of pandas, a length 1 tuple will be returned when iterating over a groupby with a grouper equal to a list of length 1. Don't supply a list with a single grouper to avoid this warning.\n",
      "  for group in time_binned:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of samples after basic filtering 21276\n",
      "Number of these samples with a valid sio2 = 16666\n",
      "Number of these samples with major element sum > 98%= 10638\n",
      "Final number of samples passed = 10638\n",
      "TODO implement min/max elevation cutoffs\n",
      "TODO implement min/max elevation cutoffs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/k2/jz_0twls1q13vbr87bqwdtr40000gn/T/ipykernel_96230/1202376196.py:166: FutureWarning: In a future version of pandas, a length 1 tuple will be returned when iterating over a groupby with a grouper equal to a list of length 1. Don't supply a list with a single grouper to avoid this warning.\n",
      "  for group in time_binned:\n"
     ]
    }
   ],
   "source": [
    "from mpl_toolkits.axes_grid1.inset_locator import inset_axes\n",
    "dpi=600\n",
    "\n",
    "#MODEL = PaleomapDictionary\n",
    "MODEL = BoschmanDictionary\n",
    "\n",
    "\n",
    "#calibration = 'FarnerLee'\n",
    "#mohometer_selection = ['gd_yb_elevation']\n",
    "\n",
    "#calibration = 'Hu'\n",
    "#mohometer_selection = ['la_yb_elevation']\n",
    "\n",
    "#calibration = 'luffi'\n",
    "#mohometer_selection = 50\n",
    "#mohometer_selection = ['gd_yb_elevation']\n",
    "\n",
    "\n",
    "plot_calibrations = [\n",
    "    ('luffi', 41),\n",
    "    ('luffi', 'la_yb_elevation'),\n",
    "    ('Hu', 'la_yb_elevation'),\n",
    "    ('Hu', 'sr_y_elevation'),\n",
    "    ('FarnerLee', 'la_yb_elevation'),\n",
    "    ('FarnerLee', 'gd_yb_elevation')\n",
    "]\n",
    "\n",
    "\n",
    "bin_size_degrees = 2.\n",
    "time_bin_size = 5.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "for calibration, mohometer_selection in plot_calibrations:\n",
    "\n",
    "\n",
    "\n",
    "    if isinstance(mohometer_selection, list):\n",
    "        mohometer_description_string = '|'.join(mohometer_selection)\n",
    "    else:\n",
    "        mohometer_description_string = str(mohometer_selection)\n",
    "\n",
    "\n",
    "    ###########################\n",
    "    # DO THE ELEVATION PLOTS   \n",
    "    ###########################\n",
    "\n",
    "    df_filt = joy.filter_the_database(df, calibration, \n",
    "                                      age_max=MODEL['maximum_time'])\n",
    "\n",
    "    elevations_df = joy.get_elevations(df_filt, \n",
    "                                       gc_interpolator_dict=gc_interpolator_dict,\n",
    "                                       calibration=calibration,\n",
    "                                       mohometer_selection=mohometer_selection)\n",
    "\n",
    "    #'''\n",
    "\n",
    "    ppdat = gpd.GeoDataFrame(elevations_df, geometry=df_filt.geometry, crs=4326).join(df_filt['age'])\n",
    "    ppdat['bin_latitude'] = np.round(ppdat.geometry.y/bin_size_degrees) * bin_size_degrees\n",
    "    ppdat['bin_age'] = np.round(ppdat['age']/time_bin_size) * time_bin_size\n",
    "    p_groups = ppdat.groupby(by=['bin_latitude', 'bin_age'])\n",
    "\n",
    "    binned_list = []\n",
    "    for g in p_groups:\n",
    "        binned_list.append([g[0][0], \n",
    "                            g[0][1],\n",
    "                            g[1].drop(columns=['age', 'bin_age', 'bin_latitude', 'geometry']).stack().median(),\n",
    "                            median_abs_deviation(g[1].drop(columns=['age', 'bin_age', 'bin_latitude', 'geometry']).stack())])\n",
    "\n",
    "    binned_df = pd.DataFrame(data=binned_list, \n",
    "                             columns=['lat', 'bin_age', 'median_elevation', 'elevation_mad']).dropna(subset=['median_elevation'])\n",
    "\n",
    "\n",
    "    def elevation_latitude_plot(reconstruction_time=None):\n",
    "        fig,ax = plt.subplots(figsize=(8,4))\n",
    "        cm = ax.scatter(binned_df['bin_age'], binned_df['lat'], c=binned_df['median_elevation'], \n",
    "                    s=20, vmin=-1000, vmax=5000, cmap='cubehelix_r')#, edgecolor='black')\n",
    "        ax.set_xlim(-5,360)\n",
    "        ax.set_ylim(-58,12)\n",
    "        ax.set_xlabel('Age [Ma]')\n",
    "        ax.set_ylabel('Latitude')\n",
    "        #ax.set_facecolor('lightgrey')\n",
    "\n",
    "        cax = inset_axes(ax, width=\"20%\", height=\"4%\", loc='lower right', borderpad=3.5)\n",
    "        cbar = plt.colorbar(cm, cax=cax, orientation='horizontal', extend='both')\n",
    "        cax.xaxis.set_ticks_position(\"bottom\")\n",
    "        cbar.ax.set_xlabel('Elevation [m]')\n",
    "        #cbar = plt.colorbar(cm)\n",
    "        #cbar.ax.set_ylabel('Elevation [m]')\n",
    "\n",
    "        if reconstruction_time is not None:\n",
    "            plt.fill_betweenx([-80,80], \n",
    "                              reconstruction_time-(time_bin_size/2.),\n",
    "                              reconstruction_time+(time_bin_size/2.),\n",
    "                              color='darkkhaki', zorder=-1, linewidth=0)\n",
    "            plt.savefig('../images/sequence_{:s}/Elevation_versus_latitude_{:s}_{:s}_{:s}_{:0.0f}Ma.png'.format(MODEL['name'], \n",
    "                                                                                                      MODEL['name'], \n",
    "                                                                                                      calibration,\n",
    "                                                                                                      mohometer_description_string,\n",
    "                                                                                                      reconstruction_time))\n",
    "        else:\n",
    "            plt.savefig('../images/Elevation_versus_latitude_{:s}_{:s}_{:s}.png'.format(MODEL['name'],\n",
    "                                                                              calibration,\n",
    "                                                                              mohometer_description_string),\n",
    "                        dpi=dpi)\n",
    "        plt.close()\n",
    "\n",
    "\n",
    "\n",
    "    elevation_latitude_plot()\n",
    "\n",
    "    for reconstruction_time in np.arange(0,MODEL['maximum_time']+time_bin_size,time_bin_size):\n",
    "        elevation_latitude_plot(reconstruction_time)\n",
    "\n",
    "    #'''\n",
    "\n",
    "\n",
    "    ###########################\n",
    "    # DO THE RESIDUAL PLOT   \n",
    "    ###########################\n",
    "\n",
    "    df_filt = MODEL['reconstruction_model'].assign_plate_ids(df_filt)\n",
    "\n",
    "    interpolator_dict = generate_time_dependent_interpolator(MODEL['raster_sequence'])\n",
    "\n",
    "    df_filt = interpolate_paleoDEM(df_filt,\n",
    "                                   MODEL['reconstruction_model'],\n",
    "                                   interpolator_dict,\n",
    "                                   anchor_plate_id=MODEL['raster_anchor_plate_id'])\n",
    "\n",
    "    elevations_residuals = joy.get_elevations(df_filt, \n",
    "                                              gc_interpolator_dict=gc_interpolator_dict,\n",
    "                                              calibration=calibration,\n",
    "                                              mohometer_selection=mohometer_selection)\n",
    "\n",
    "    elevations_residuals = elevations_residuals.sub(df_filt['PaleoDEM'], axis=0)\n",
    "\n",
    "\n",
    "    ppdat = gpd.GeoDataFrame(elevations_residuals, geometry=df_filt.geometry, crs=4326)\n",
    "    ppdat = ppdat.join(df_filt['age'])\n",
    "\n",
    "    ppdat['bin_latitude'] = np.round(ppdat.geometry.y/bin_size_degrees) * bin_size_degrees\n",
    "    ppdat['bin_age'] = np.round(ppdat['age']/time_bin_size) * time_bin_size\n",
    "\n",
    "    p_groups = ppdat.groupby(by=['bin_latitude', 'bin_age'])\n",
    "\n",
    "    binned_list = []\n",
    "    for g in p_groups:\n",
    "        binned_list.append([g[0][0], \n",
    "                            g[0][1],\n",
    "                            g[1].drop(columns=['age', 'bin_age', 'bin_latitude', 'geometry']).stack().median(),\n",
    "                            median_abs_deviation(g[1].drop(columns=['age', 'bin_age', 'bin_latitude', 'geometry']).stack(), nan_policy='omit')])\n",
    "\n",
    "    binned_df = pd.DataFrame(data=binned_list, \n",
    "                             columns=['lat', 'bin_age', 'median_elevation', 'elevation_mad']).dropna(subset=['median_elevation'])\n",
    "\n",
    "\n",
    "\n",
    "    #################\n",
    "    time_binned = ppdat.groupby(by=['bin_age'])\n",
    "\n",
    "\n",
    "    median_elevations = []\n",
    "    elevation_violins = []\n",
    "    for group in time_binned:\n",
    "        if not group[1].empty:\n",
    "            median_elevations.append(group[1].drop(columns=['age', 'bin_age', 'bin_latitude', 'geometry']).stack().median())\n",
    "            elevation_violins.append(group[1].drop(columns=['age', 'bin_age', 'bin_latitude', 'geometry']).stack())\n",
    "        else:\n",
    "            median_elevations.append(np.nan)\n",
    "            elevation_violins.append([np.nan,np.nan])\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    fig = plt.figure(figsize=(8,6))\n",
    "    gs = fig.add_gridspec(nrows=2, ncols=1, wspace=0.1, hspace=.1, height_ratios=[1,3])\n",
    "\n",
    "    ax = fig.add_subplot(gs[0])\n",
    "    parts = ax.boxplot(elevation_violins, positions=list(time_binned.groups.keys()), \n",
    "                       widths=4, \n",
    "                       patch_artist=True, manage_ticks=False, \n",
    "                       whis=[5, 95], showfliers=False)\n",
    "    for pc in parts['boxes']:\n",
    "        pc.set_facecolor('gray')\n",
    "        pc.set_alpha(0.5)\n",
    "        pc.set_edgecolor('black')  \n",
    "    ax.axhline(y=0, color='black', alpha=0.5)\n",
    "    ax.set_ylim(-4000,4000)\n",
    "    ax.set_xlim(-5, 360)\n",
    "    ax.set_xticklabels([])\n",
    "    ax.set_ylabel('Residual Elevation [m]')\n",
    "    #ax.grid()\n",
    "\n",
    "\n",
    "    ax = fig.add_subplot(gs[1])\n",
    "    cm = ax.scatter(binned_df['bin_age'], binned_df['lat'], c=binned_df['median_elevation'], \n",
    "                s=16, marker='o', vmin=-5000, vmax=5000, cmap='seismic')#, edgecolor='black')\n",
    "    ax.set_xlim(-5,360)\n",
    "    ax.set_ylim(-58,12)\n",
    "    ax.set_xlabel('Age [Ma]')\n",
    "    ax.set_ylabel('Latitude')\n",
    "    #ax.set_facecolor('lightgrey')\n",
    "\n",
    "    cax = inset_axes(ax, width=\"20%\", height=\"4%\", loc='lower right', borderpad=3.5)\n",
    "    cbar = plt.colorbar(cm, cax=cax, orientation='horizontal', extend='both')\n",
    "    cax.xaxis.set_ticks_position(\"bottom\")\n",
    "    cbar.ax.set_xlabel('Residual Elevation [m]')\n",
    "\n",
    "    plt.savefig('../images/Elevation_residuals_versus_latitude_{:s}_{:s}_{:s}.png'.format(MODEL['name'],\n",
    "                                                                                calibration,\n",
    "                                                                                mohometer_description_string), \n",
    "               dpi=dpi)\n",
    "    plt.close()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "id": "3ac5d37d-fdb2-4c2f-935d-4260ba091906",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5615"
      ]
     },
     "execution_count": 151,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sum([len(n) for n in elevation_violins])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "id": "773a65ac-e845-40c5-8734-50cbcc1dcb35",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10472\n",
      "219\n",
      "142\n",
      "43\n",
      "72\n",
      "28\n",
      "16\n",
      "8\n",
      "19\n",
      "17\n",
      "7\n",
      "52\n",
      "13\n",
      "37\n",
      "15\n",
      "31\n",
      "19\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/k2/jz_0twls1q13vbr87bqwdtr40000gn/T/ipykernel_96230/1672162648.py:1: FutureWarning: In a future version of pandas, a length 1 tuple will be returned when iterating over a groupby with a grouper equal to a list of length 1. Don't supply a list with a single grouper to avoid this warning.\n",
      "  for group in time_binned: #.keys()\n"
     ]
    }
   ],
   "source": [
    "for group in time_binned: #.keys()\n",
    "    print(len(group[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "id": "e2055fb1-c00c-4906-8195-1883881c08fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/k2/jz_0twls1q13vbr87bqwdtr40000gn/T/ipykernel_96230/4278864852.py:11: FutureWarning: In a future version of pandas, a length 1 tuple will be returned when iterating over a groupby with a grouper equal to a list of length 1. Don't supply a list with a single grouper to avoid this warning.\n",
      "  [len(g[1].groupby(by=['bin_latitude', 'bin_longitude']).groups.keys()) for g in p_groups]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[189, 33, 26, 18, 25, 16, 7, 4, 1, 5, 1, 4, 3, 9, 3, 2, 5]"
      ]
     },
     "execution_count": 184,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bin_size_degrees = 1.\n",
    "ppdat = gpd.GeoDataFrame(elevations_df, geometry=df_filt.geometry, crs=4326).join(df_filt['age'])\n",
    "ppdat['bin_latitude'] = np.round(ppdat.geometry.y/bin_size_degrees) * bin_size_degrees\n",
    "ppdat['bin_longitude'] = np.round(ppdat.geometry.x/bin_size_degrees) * bin_size_degrees\n",
    "ppdat['bin_age'] = np.round(ppdat['age']/time_bin_size) * time_bin_size\n",
    "p_groups = ppdat.groupby(by=['bin_age'])\n",
    "\n",
    "#for g in p_groups:\n",
    "#    print(len(g[1].groupby(by=['bin_latitude', 'bin_longitude']).groups.keys()))\n",
    "\n",
    "[len(g[1].groupby(by=['bin_latitude', 'bin_longitude']).groups.keys()) for g in p_groups]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "id": "900c314e-5570-4d03-9e1b-ed9ec03fca35",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of samples after basic filtering 23380\n",
      "Final number of samples passed = 17999\n",
      "TODO implement min/max elevation cutoffs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/k2/jz_0twls1q13vbr87bqwdtr40000gn/T/ipykernel_96230/2748258588.py:45: FutureWarning: In a future version of pandas, a length 1 tuple will be returned when iterating over a groupby with a grouper equal to a list of length 1. Don't supply a list with a single grouper to avoid this warning.\n",
      "  for g in p_groups:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of samples after basic filtering 23380\n",
      "Final number of samples passed = 17999\n",
      "TODO implement min/max elevation cutoffs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/k2/jz_0twls1q13vbr87bqwdtr40000gn/T/ipykernel_96230/2748258588.py:45: FutureWarning: In a future version of pandas, a length 1 tuple will be returned when iterating over a groupby with a grouper equal to a list of length 1. Don't supply a list with a single grouper to avoid this warning.\n",
      "  for g in p_groups:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of samples after basic filtering 23380\n",
      "Number of samples with 55<=sio2<=70 = 10822\n",
      "Number of these samples with 1<=mgo<=4 = 8344\n",
      "Number of these samples with 0.05<=rb/sr<=0.25 = 4517\n",
      "Final number of samples passed = 4517\n",
      "TODO implement min/max elevation cutoffs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/k2/jz_0twls1q13vbr87bqwdtr40000gn/T/ipykernel_96230/2748258588.py:45: FutureWarning: In a future version of pandas, a length 1 tuple will be returned when iterating over a groupby with a grouper equal to a list of length 1. Don't supply a list with a single grouper to avoid this warning.\n",
      "  for g in p_groups:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of samples after basic filtering 23380\n",
      "Number of samples with 55<=sio2<=70 = 10822\n",
      "Number of these samples with 1<=mgo<=4 = 8344\n",
      "Number of these samples with 0.05<=rb/sr<=0.25 = 4517\n",
      "Final number of samples passed = 4517\n",
      "TODO implement min/max elevation cutoffs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/k2/jz_0twls1q13vbr87bqwdtr40000gn/T/ipykernel_96230/2748258588.py:45: FutureWarning: In a future version of pandas, a length 1 tuple will be returned when iterating over a groupby with a grouper equal to a list of length 1. Don't supply a list with a single grouper to avoid this warning.\n",
      "  for g in p_groups:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of samples after basic filtering 23380\n",
      "Number of these samples with a valid sio2 = 18521\n",
      "Number of these samples with major element sum > 98%= 11653\n",
      "Final number of samples passed = 11653\n",
      "TODO implement min/max elevation cutoffs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/k2/jz_0twls1q13vbr87bqwdtr40000gn/T/ipykernel_96230/2748258588.py:45: FutureWarning: In a future version of pandas, a length 1 tuple will be returned when iterating over a groupby with a grouper equal to a list of length 1. Don't supply a list with a single grouper to avoid this warning.\n",
      "  for g in p_groups:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of samples after basic filtering 23380\n",
      "Number of these samples with a valid sio2 = 18521\n",
      "Number of these samples with major element sum > 98%= 11653\n",
      "Final number of samples passed = 11653\n",
      "TODO implement min/max elevation cutoffs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/k2/jz_0twls1q13vbr87bqwdtr40000gn/T/ipykernel_96230/2748258588.py:45: FutureWarning: In a future version of pandas, a length 1 tuple will be returned when iterating over a groupby with a grouper equal to a list of length 1. Don't supply a list with a single grouper to avoid this warning.\n",
      "  for g in p_groups:\n"
     ]
    }
   ],
   "source": [
    "fig,ax = plt.subplots(nrows=2, figsize=(8,9))\n",
    "\n",
    "linewidth = 2\n",
    "colors = ['SteelBlue', 'SkyBlue', 'Red', 'HotPink', 'Gold', 'Orange']\n",
    "\n",
    "for i, (calibration, mohometer_selection) in enumerate(plot_calibrations):\n",
    "\n",
    "    if isinstance(mohometer_selection, list):\n",
    "        mohometer_description_string = '|'.join(mohometer_selection)\n",
    "    elif isinstance(mohometer_selection, int):\n",
    "        mohometer_description_string = 'Best {:s} mohometers'.format(str(mohometer_selection))\n",
    "    else:\n",
    "        mohometer_description_string = str(mohometer_selection)\n",
    "\n",
    "\n",
    "    ###########################\n",
    "    # DO THE ELEVATION PLOTS   \n",
    "    ###########################\n",
    "\n",
    "    df_filt = joy.filter_the_database(df, calibration,\n",
    "                                      age_max=350)\n",
    "                                      #age_max=MODEL['maximum_time'])\n",
    "\n",
    "    elevations_df = joy.get_elevations(df_filt, \n",
    "                                       gc_interpolator_dict=gc_interpolator_dict,\n",
    "                                       calibration=calibration,\n",
    "                                       mohometer_selection=mohometer_selection)\n",
    "    \n",
    "    bin_size_degrees = 1.\n",
    "    ppdat = gpd.GeoDataFrame(elevations_df, geometry=df_filt.geometry, crs=4326).join(df_filt['age'])\n",
    "    ppdat['bin_latitude'] = np.round(ppdat.geometry.y/bin_size_degrees) * bin_size_degrees\n",
    "    ppdat['bin_longitude'] = np.round(ppdat.geometry.x/bin_size_degrees) * bin_size_degrees\n",
    "    ppdat['bin_age'] = np.round(ppdat['age']/time_bin_size) * time_bin_size\n",
    "    p_groups = ppdat.groupby(by=['bin_age'])\n",
    "\n",
    "    #for g in p_groups:\n",
    "    #    print(len(g[1].groupby(by=['bin_latitude', 'bin_longitude']).groups.keys()))\n",
    "\n",
    "    #nbins = [len(g[1].groupby(by=['bin_latitude', 'bin_longitude']).groups.keys()) for g in p_groups]\n",
    "    \n",
    "    age_keys = []\n",
    "    number_of_bins_time_series = []\n",
    "    number_of_values_time_series = []\n",
    "\n",
    "    for g in p_groups:\n",
    "        age_keys.append(g[0])\n",
    "        number_of_bins = 0\n",
    "        #number_of_values = 0\n",
    "        for h in g[1].groupby(by=['bin_latitude', 'bin_longitude']):\n",
    "            m = h[1].drop(columns=['age', 'bin_age', 'bin_longitude', 'bin_latitude', 'geometry']).dropna(axis=0, how='all').stack().median()  #.groups.keys()\n",
    "            #c = h[1].drop(columns=['age', 'bin_age', 'bin_longitude', 'bin_latitude', 'geometry']).stack().notna().sum()\n",
    "            if ~np.isnan(m): \n",
    "                number_of_bins+=1\n",
    "            #if ~np.isnan(c):\n",
    "                \n",
    "        number_of_bins_time_series.append(number_of_bins)\n",
    "        number_of_values_time_series.append(g[1].drop(columns=['age', 'bin_age', 'bin_longitude', 'bin_latitude', 'geometry']).stack().notna().sum())\n",
    "\n",
    "    \n",
    "    \n",
    "    \n",
    "    ax[0].plot(age_keys, number_of_values_time_series, \n",
    "               color=colors[i],\n",
    "               linewidth=linewidth,\n",
    "               label='{:s}, {:s}'.format(calibration, mohometer_description_string))\n",
    "    ax[1].plot(age_keys, number_of_bins_time_series, \n",
    "               color=colors[i],\n",
    "               linewidth=linewidth,\n",
    "               label='{:s}, {:s}'.format(calibration, mohometer_description_string))\n",
    "    #break\n",
    "\n",
    "\n",
    "ax[1].legend()\n",
    "ax[1].set_xlabel('Reconstruction Age [Ma]')\n",
    "ax[1].set_ylabel('Number of 1 degree bins')\n",
    "ax[0].set_ylabel('Number of Values')\n",
    "ax[0].set_xticklabels('')\n",
    "#ax[0].grid()\n",
    "#ax[1].grid()\n",
    "\n",
    "for _ax in ax:\n",
    "    _ax.grid(which='both', axis='y', linestyle='--')\n",
    "    _ax.set_yscale('log')\n",
    "\n",
    "ax[0].set_ylim(1,3.5e5)\n",
    "ax[1].set_ylim(1,300)\n",
    "\n",
    "#plt.show()\n",
    "plt.savefig('../images/data_filtering_comparison.png', dpi=600)\n",
    "plt.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "id": "7f6b0841-37e3-4e09-9fab-c98d2b19fcd7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "115"
      ]
     },
     "execution_count": 232,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "h[1].drop(columns=['age', 'bin_age', 'bin_longitude', 'bin_latitude', 'geometry']).stack().notna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0e5e5c4-1bc9-43ce-9642-55688dd69aaa",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:pygmt9]",
   "language": "python",
   "name": "conda-env-pygmt9-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
